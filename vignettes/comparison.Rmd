---
title: "Comparison of Pollen Traps"
subtitle: "Evaluation of Similarity and Robustness of Eight Pollen Traps Located in Payerne During the Blooming Season 2019"
author: "Simon Adamov"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
always_allow_html: true
output:
  html_document:
    df_print: paged 
  pdf_document: default
  word_document: default
---

# Setup

This project is using renv dependency management, for more info: 
https://cran.r-project.org/web/packages/renv/vignettes/renv.html
The .RProfile is optimized for an interactive session in VSCode.

```{r setup}
knitr::opts_chunk$set(
  echo = FALSE,
  error = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.retina = 3,
  fig.width = 10,
  fig.height = 7,
  out.width = "100%",
  out.height = "100%"
)
# This project is using renv dependency management, for more info:
# https://cran.r-project.org/web/packages/renv/vignettes/renv.html

library(caTools)
library(httpgd)
library(languageserver)
library(MASS)
library(tidyverse)
library(magrittr)
library(lubridate)
library(ggpubr)
library(here)
library(kableExtra)
library(RColorBrewer)
library(padr)
library(psych)
library(nparcomp)

library(conflicted)
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
conflict_prefer("extract", "magrittr")

devtools::load_all()

# Due to old R-Version some packages must be installed from CRAN Archive,
# in order to knit markdown documents.
# caTools@1.17.1.1
# pbkrtest@0.4-7
# nloptr@1.2.2
# foreign@0.8-76
# devtools@2.2.1
# usethis@1.5.1
# devtools@2.2.1
```

# Data Import

The data was prepared by Fiona Tummon and stored in the /data-raw Folder.
Eight different Pollen Traps were situated on the roof in Payerne and continously measured pollen 
grains between 19.04.2019 - 31.05.2019.
For the sake of simplicity we only look at concentrations of total pollen (i.e. the sum of all pollen taxa).
The concentrations were temporally averaged to obtain three different timeseries:

- Hourly averages
- 6-hour averages (hourly values from 00:00 to 05:00, 06:00 to 11:00, ...)
- Daily averages (hourly values from 00:00 to 23:00)

The preprocessed data is available to the reader in the /data folder. 
In /data-raw/preproc.R the preprocessing is documented.
The data has missing values in the Hirst2, Poleno(1 and 3) and RapidE timeseries. 
For Poleno there was no clear way to distinguish hours without Pollen and hours with missing data.
To be as conservative as possible all dates with missing pollen measurements in the Poleno timeseries were removed.
For Poleno1 calibration was carried out on 11 days.
For Poleno3 calibration was carried out on 6 days.
For RapidE software mulfunctioned (it seems) during 9 days, as discussed with MDS.
These full 21 unique days were excluded from the analysis for all traps and temporal resolutions.
The whole analysis is based on the data exlcuding these 21 days, except for the timeseries plot (figure 1).
For the timeseries the full timeseries are displayed, which includes NAs for Poleno and Rapid-E.

The following eight traps are being compared:

- Hirst = Mean(Hirst 1, Hirst 2) / 1.35 which will be the standard to compare against. Historically, we have the most experience with Hirst traps.
- Hund (no hourly values)
- KH-A
- KH-B
- Poleno 1
- Poleno 3
- Rapide
- WIBS (no hourly values)


```{r data}
load(paste0(here(), "/data/pollen.rda"))
load(paste0(here(), "/data/pollen_full.rda"))
aggregation <- c("daily", "sixhour", "hourly")
map(aggregation, ~ pollen %>% extract2(.x))

```

# Comparison

## Some Tables

The number of traps measuring pollen simultaneously decreases with higher temporal resolution.

```{r ntraps}
number_of_measurements <- map(pollen, ~ .x %>%
  group_by(trap, date, hour) %>%
  mutate(ntraps = as.integer(as.integer(conc) != 0)) %>%
  ungroup() %>%
  group_by(date, hour) %>%
  summarise(ntraps = sum(ntraps)) %>%
  ungroup() %>%
  mutate(ntraps = factor(ntraps)))

timesteps <- map(number_of_measurements, ~ .x %>% nrow())

kable_ntraps <- pmap(
  list(number_of_measurements, aggregation, c(8, 8, 6)),
  function(first, second, third) {
    first %>%
      count(ntraps) %>%
      mutate(
        freq = scales::percent(n / nrow(first), accuracy = 0.1),
        res = second,
        tottraps = paste0(ntraps, " / ", third)
      )
  }
) %>%
  bind_rows() %>%
  select(
    "Temporal Resolution" = res,
    "Number of Traps Measuring" = tottraps,
    "Frequency of Occurence" = freq
  ) %>%
  kable(escape = FALSE) %>%
  kable_styling(c("striped", "condensed"),
                full_width = FALSE,
                font_size = 20) %>%
  column_spec(1, border_right = TRUE) %>%
  collapse_rows(columns = 1) %>%
  pack_rows(NULL, 1, 1, indent = FALSE) %>%
  pack_rows(NULL, 2, 4, indent = FALSE) %>%
  pack_rows(NULL, 5, 7, indent = FALSE)

save_kable(kable_ntraps, file = paste0(here(), "/tables/table1_ntraps.html"))
kable_ntraps
```

Several metrics were calculated: the frequency of occurrence was obtained by counting 
the number of days on which pollen were detected; 
the average was calculated by averaging values for total pollen measurements during the study period; 
and the Seasonal Pollen Integral (SPI) was calculated by integrating the concentrations of total pollen
over the study period. (Mandrioli et al., 1998).

These metrics are well-known and a standard part of any Pollen Measurement study. It is common to investigate 
individual pollen species during their blooming period. 
Here we are calculating them for total pollen, which might not be as meaningful, but can function as a 
crude mechanism of comparison.

```{r daily_tables}
pol_occurence <- pollen$daily %>%
  group_by(trap) %>%
  summarise(occurence = sum(conc != 0)) %>%
  ungroup()

pol_maximum <- pollen$daily %>%
  group_by(trap) %>%
  summarise(maximum = max(conc)) %>%
  ungroup()

pol_average <- pollen$daily %>%
  group_by(trap) %>%
  summarise(average = mean(conc)) %>%
  ungroup()
  
pol_median <- pollen$daily %>%
  group_by(trap) %>%
  summarise(median = median(conc)) %>%
  ungroup()

pol_spi <- pollen$daily %>% # Seasonal Pollen Integral
  group_by(trap) %>%
  summarise(spi = sum(conc)) %>%
  ungroup()

kable_metrics <- pol_occurence %>%
  inner_join(pol_maximum, by = "trap") %>%
  inner_join(pol_average, by = "trap") %>%
  inner_join(pol_median, by = "trap") %>%
  inner_join(pol_spi, by = "trap") %>%
  mutate(across(where(is.numeric), round)) %>%
  kable(escape = FALSE) %>%
  kable_styling(c("striped", "condensed"),
                full_width = FALSE,
                font_size = 20) %>%
  column_spec(1, italic = TRUE, border_right = TRUE)

save_kable(kable_metrics, file = paste0(here(), "/tables/table2_metrics.html"))
kable_metrics
```

We can see that already for daily values the differences between traps are substantial.
Next, we investigate how large the spread within the measurements is for each trap for different temporal resolutions.
We can see that not only the absolute measurements but also the spread of the measurements varies largely between traps.


```{r variability_tables}
kable_variability <- map(
  pollen, ~ .x %>%
    group_by(trap) %>%
    summarise(
      sd = sd(conc),
      mean = mean(conc),
      se = sd / n(),
      cv = sd / mean
    ) %>%
    mutate(across(c(sd, mean), round)) %>%
    mutate(across(c(se, cv), round, 2))
) %>%
  reduce(full_join, by = "trap") %>%
  mutate(across(everything(), replace_na, "-")) %>%
  setNames(c("Trap", rep(c("sd", "mean", "se", "cv"), times = 3))) %>%
  kable(escape = FALSE) %>%
  kable_styling(c("striped", "condensed"),
    full_width = FALSE,
    font_size = 20
  ) %>%
  add_header_above(c(
    " " = 1, "Daily Averages" = 4,
    "Six-Hour Averages" = 4,
    "Hourly Averages" = 4
  )) %>%
  column_spec(1, italic = TRUE, border_right = TRUE) %>%
  column_spec(c(5, 9, 13), border_right = TRUE)

save_kable(kable_variability,
  file = paste0(here(), "/tables/table3_variability.html")
)
kable_variability
```

Setting a coarser temporal resolution reduces the variability in the measurements.
The coefficient of variation (CV) for the Polenos is the largest in the study. 
On the other side of the spectrum, RapidE has the lowest spread in the measurements.

# Some Plots

```{r theme}
theme_set(theme_minimal(base_size = 14) + theme(legend.title = element_blank()))
traps_cols <- RColorBrewer::brewer.pal(8, "Set2")[c(1, 7, 4, 6, 2, 3, 5, 8)]
traps_names <- pollen$daily$trap %>%
  unique() %>%
  sort()
names(traps_cols) <- traps_names
```

## Timeseries

The differences between the traps are quite substantial looking at these timeseries. 
Most traps were able to identify days with higher pollen occurence, 
but the performance varies a lot (maybe also species dependent).
The concentrations are scaled here to match Hirst (conc / mean(trap_i) * mean(trap_hirst)).
Where the mean for each trap was calculated across the full period.


```{r timeseries}
pmap(
  list(
    pollen_full,
    aggregation,
    c("2019-05-31", "2019-04-25", "2019-04-22")
  ),
  function(first, second, third, fourth) {
    gg_time1 <- first %>%
      group_by(trap) %>%
      mutate(mean = mean(conc, na.rm = TRUE)) %>%
      left_join(
        first %>%
          filter(trap == "hirst") %>%
          group_by(trap) %>%
          mutate(mean = mean(conc, na.rm = TRUE)) %>%
          ungroup() %>%
          select(date, mean_hirst = mean),
        by = "date"
      ) %>%
      mutate(conc = conc / mean * mean_hirst) %>%
      pad(
        start_val = min(first %>% pull(datetime)),
        end_val = max(first %>% pull(datetime)),
        group = c("trap"),
        by = "datetime"
      ) %>%
      filter(date < date(third)) %>%
      ggplot(aes(x = datetime)) +
      geom_line(aes(y = conc, col = trap), alpha = 0.8) +
      labs(y = "Mean Conc. [Pollen/mÂ³]", x = "") +
      ggtitle(paste0(
        "Timeseries of ",
        tools::toTitleCase(second),
        " Total Pollen Concentrations"
      )) +
      scale_color_manual(values = traps_cols)

    ggsave(paste0(here(), "/figures/fig1_timeseries_", second, ".png"),
      gg_time1,
      width = 12, height = 9, dpi = 300
    )
    gg_time1
  }
)
```

Looking at the boxplots we can see how the spread in the measurements increases with higher temporal resolution; especially for Hirst.
Wibs, Rapide and KHB measured less pollen than the other traps, overall.

```{r boxplot}
map2(pollen, aggregation, function(first, second) {
  gg_box1 <- first %>%
    ggplot() +
    geom_boxplot(aes(y = log10(conc + 1), fill = trap), alpha = 0.8) +
    labs(y = "Log Mean Conc. [Pollen/mÂ³]", x = "") +
    scale_fill_manual(values = traps_cols) +
    ggtitle(paste0(
      "Boxplot of ",
      tools::toTitleCase(second),
      " Total Pollen Concentrations"
    )) +
    theme(legend.position = "bottom") +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
    coord_cartesian(ylim = c(0, 3))

  ggsave(paste0(here(), "/figures/fig2_boxplot_", second, ".png"),
    gg_box1,
    width = 12, height = 9, dpi = 300
  )
  gg_box1
})
```

Looking at the histograms, the findings above are solidified.
Furthermore, we clearly see the discrete timeseries for higher resolutions as produced by 
Hirst Traps and Manual Counting.

```{r histogram}

label_xy <- c(6, 21, 175)

pmap(list(pollen, aggregation, label_xy), function(first, second, third) {
  sd_comp <- first %>%
    group_by(trap) %>%
    summarise(sd = sd(conc))

  gg_hist1 <- first %>%
    ggplot() +
    geom_histogram(aes(y = log10(conc + 1), fill = trap),
      alpha = 0.8, binwidth = 0.1
    ) +
    geom_label(
      data = sd_comp,
      aes(
        label = paste(
          "Standard Deviation:\n",
          round(sd),
          "Pollen / mÂ³"
        ),
        x = third,
        y = 0.7, group = trap
      ), size = 3
    ) +
    facet_wrap(vars(trap), ncol = 3) +
    theme(legend.position = "bottom") +
    coord_flip() +
    labs(
      x = "Occurence of Pollen Concentrations",
      y = "Log Mean Conc. [Pollen/mÂ³]"
    ) +
    ggtitle(paste0(
      "Histogram of ",
      tools::toTitleCase(second),
      " Total Pollen Concentrations"
    )) +
    scale_fill_manual(values = traps_cols)

  ggsave(paste0(here(), "/figures/fig3_histogram_", second, ".png"),
    gg_hist1,
    width = 12, height = 9, dpi = 300
  )
  gg_hist1
})

```

# Relative Errors

Looking at (absolute) relative differences between Hirst and the other traps, 
one can investigate which traps diverge the most from the historically used Hirst traps.
The general findings seem to persist across different temporal resolutions.
It is common to exclude measurements below a 10 pollengrains per m^3 threshold.

```{r errordata}

conc_groups <- c(
    "Group10_20",
    "Group20_50",
    "Group50_100",
    "Group100_300",
    "Group300"
  )

errors <- map(pollen, ~ .x %>%
  # Here we previously used the common mean of all traps,
  # but now decided to compare to Hirst
  pivot_wider(names_from = trap, values_from = conc) %>%
  # Divsion by zero otherwise leads to many NAs, especially for hourly values
  mutate(mean = hirst)) %>%
  map_at(3, ~ .x %>%
    mutate(
      hund = NA_real_,
      wibs = NA_real_
    )) %>%
  map(~ .x %>%
    select(datetime, date, hour, mean, all_of(traps_names)) %>%
    pivot_longer(hirst:wibs, names_to = "trap", values_to = "conc") %>%
    mutate(reldiff = abs(conc - mean) / mean,
           trap = factor(trap, levels = traps_names)) %>%
    filter(mean > 10))
  
errors_conc <- map(errors, ~ .x %>%
  mutate(
    group = case_when(
      mean >= 10 & mean < 20 ~ "Group10_20",
      mean >= 20 & mean < 50 ~ "Group20_50",
      mean >= 50 & mean < 100 ~ "Group50_100",
      mean >= 100 & mean < 300 ~ "Group100_300",
      mean >= 300 ~ "Group300"
    ),
    group = factor(group, levels = conc_groups)))

```

The relative differences from the Hirst mean are substantial, Hund and Poleno measure more pollen than Hirst; Wibs, KHB and Rapide measure less. 
For higher temporal Resolutions the differences become larger. Please note that some outliers (black dots) were cut off, reaching up to almost 5000%.
This does not mean that they measure worse than the rest. There is no golden standard in measuring pollen.


```{r relerrors}
map2(errors, aggregation, function(first, second) {
  gg_errors1 <- first %>%
    filter(trap != "hirst") %>%
    ggplot(aes(y = reldiff, fill = trap)) +
    geom_boxplot() +
    labs(y = "Relative Difference from Hirst", x = "") +
    scale_fill_manual(values = traps_cols) +
    ggtitle(paste0(
      "Boxplot of ",
      tools::toTitleCase(second),
      " Measurement Differences from Hirst"
    )) +
    theme(legend.position = "bottom") +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
    coord_cartesian(ylim = c(0, 3))

  ggsave(paste0(here(), "/figures/fig4_relerror_boxplot_", second, ".png"),
    gg_errors1,
    width = 12, height = 9, dpi = 300
  )
  gg_errors1
})
```

The spread in the measurement seems to correlate with the total pollen concentrations.
For lower concentrations Poleno and Hund are measuring more then the Hirst (better capture?).
KHB, Wibs and Rapide are consitently measuring less pollen than the other traps in the study.
Be careful, these are log scales, as the differences can become very large. 
A value of 1 on the y axis reflects a 10x larger value for that trap compared to Hirst.
```{r concerrors}
map2(errors_conc, aggregation, function(first, second) {
  gg_conc1 <- first %>%
  filter(trap != "hirst") %>%
    ggplot(aes(y = log10(reldiff), fill = trap)) +
    geom_boxplot() +
    labs(y = "Relative Difference from Hirst Mean (Log)", x = "") +
    scale_fill_manual(values = traps_cols) +
    ggtitle(paste0(
      "Boxplot of ",
      tools::toTitleCase(second),
      " Log. Measurement Differences"
    )) +
    theme(legend.position = "bottom") +
    annotation_logticks(sides = "l") +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
    coord_cartesian(ylim = c(-1.5, 1.5)) +
    facet_wrap(~group)

  ggsave(paste0(here(), "/figures/fig5_relerror_conc_boxplot_", second, ".png"),
    gg_conc1,
    width = 12, height = 9, dpi = 300
  )
  gg_conc1
})
```

The table shows the relative differences from Hirst for all traps combined.

```{r relerror_kable}

kable_error <- map(errors_conc, ~.x %>%
  na.omit() %>% # We introduced NAs for hund and wibs for nicer plots above.
  group_by(group) %>%
  summarise(
    mean = mean(reldiff),
    sd = sd(reldiff),
    q25 = quantile(reldiff, 0.25),
    median = median(reldiff),
    q75 = quantile(reldiff, 0.75)
  ) %>%
  ungroup %>%
  bind_rows(
    .x %>%
    na.omit() %>%
      summarise(
        mean = mean(reldiff),
        sd = sd(reldiff),
        q25 = quantile(reldiff, 0.25),
        median = median(reldiff),
        q75 = quantile(reldiff, 0.75)
      ) %>%
      mutate(group = "all") %>%
      ungroup())) %>%
  bind_rows() %>%
  mutate(across(!group, round, 2)) %>%
    kable(escape = FALSE) %>%
  kable_styling(c("striped", "condensed"),
    full_width = FALSE,
    font_size = 20
  ) %>%
  pack_rows("Daily", 1, 5, indent = FALSE) %>%
  pack_rows("Six-Hour", 6, 11, indent = FALSE) %>%
  pack_rows("Hourly", 12, 17, indent = FALSE) %>%
  add_header_above(c("Relative Differences for All Traps Combined" = 6))

save_kable(kable_error,
  file = paste0(here(), "/tables/table4_relerror.html")
)

kable_error

```

The density plots outline the behavior of all traps for different concentration categories 
(based on the Hirst mean).
KHB and Rapide stand out, usually measuring less than the others for concentrations below 300.
Poleno further stand out with more pollen measured during periods of low concentrations.

```{r concerror_kable}
map2(errors_conc, aggregation, function(data, second) {
  gg_conc_dens <- map2(
    conc_groups,
    c(75, 200, 200, 300, 1000),
    function(first, second) {
      conc_plot_data <- data %>%
        filter(group == first)

      if (nrow(conc_plot_data) > 0) {
        conc_plot_data %>%
          ggplot() +
          geom_density(aes(x = conc, col = trap, fill = trap), alpha = 0.1) +
          scale_fill_manual(
            values = traps_cols,
            aesthetics = c("colour", "fill")
          ) +
          ggtitle(first) +
          theme(legend.position = "bottom") +
          coord_cartesian(xlim = c(0, second))
      }
    }
  )
  gg_density1 <- ggarrange(
    plotlist = gg_conc_dens
  ) %>%
    annotate_figure(
      top = text_grob(paste(
        "Density Plot of",
        second,
        "Total Pollen Measurements"
      ),
      size = 16
      )
    )

  ggsave(paste0(here(), "/figures/fig6_conc_density_", second, ".png"),
    gg_density1,
    width = 12, height = 9, dpi = 300
  )
  gg_density1
})

```

# Resdiual Analysis

Pollen data usually does not fulfil the assumption of ANOVA. We want to check this in the following.

- are the errors normally distributed?

In a QQ-plot we plot the empirical quantiles (âwhat we see in the dataâ) vs. the theoretical quantiles 
(âwhat we expect from the modelâ). The plot should show a more or less straight line if the 
distributional assumption is correct. By default, a standard normal distribution is the theoretical 
âreference distributionâ.

```{r log}
pollen_10 <- map(pollen, ~ .x %>%
  pivot_wider(names_from = trap, values_from = conc) %>%
  filter(hirst > 10) %>%
  pivot_longer(KHA:hirst, names_to = "trap", values_to = "conc") %>%
  mutate(trap = factor(trap),
         trap = relevel(trap, ref = "hirst")))

pollen_10_log <- map(pollen, ~ .x %>% mutate(conc = log(conc + 1)))
```

The default contrast is contr treatment and with relevel we made sure that Hirst is the reference level.

```{r QQ}
map2(pollen_10, pollen_10_log, function(first, second) {
  fit_anova <- aov(conc ~ trap,
    data = first)

  fit_anova_log <- aov(conc ~ trap,
    data = second
  )

  gg_res1 <- tibble(residuals = residuals(fit_anova, type = "pearson")) %>%
    ggplot(aes(sample = residuals)) +
    stat_qq(col = traps_cols[1]) +
    stat_qq_line(col = traps_cols[5])

  gg_res2 <- tibble(residuals = residuals(fit_anova_log, type = "pearson")) %>%
    ggplot(aes(sample = residuals)) +
    stat_qq(col = traps_cols[1]) +
    stat_qq_line(col = traps_cols[5])

  ggarrange(gg_res1, gg_res2, nrow = 1) %>%
    annotate_figure(top = paste(
      "QQ-Plot for the ANOVA Residuals With",
      "(right) and Without Logarithmizing"
    ))
})
```


- is the error variance constant?
- do the errors have mean zero?

The Tukey-Anscombe plot plots the residuals vs. the fitted values. 
It allows us to check whether the residuals have constant variance and whether the residuals have mean zero 
(i.e. they donât show any deterministic pattern). 

```{r tukey}
map2(pollen_10, pollen_10_log, function(first, second) {
  fit_anova <- aov(conc ~ trap,
    data = first
  )

  fit_anova_log <- aov(conc ~ trap,
    data = second
  )

  gg_tukey1 <- tibble(
    resid = residuals(fit_anova,
      type = "pearson"
    ),
    fitted = fit_anova$fitted.values
  ) %>%
    ggplot(aes(x = fitted, y = resid)) +
    geom_point(
      alpha = 0.5,
      position = position_jitter(
        width = 5,
        height = 0
      ),
      col = traps_cols[1]
    ) +
    # geom_smooth(method = "loess", col = traps_cols[4]) +
    geom_abline(slope = 0, intercept = 0, col = traps_cols[3], alpha = 0.9) +
    coord_cartesian(ylim = c(-500, 500))

  gg_tukey2 <-
    tibble(
      resid = residuals(fit_anova_log,
        type = "pearson"
      ),
      fitted = fit_anova_log$fitted.values
    ) %>%
    ggplot(aes(x = fitted, y = resid)) +
    geom_point(
      alpha = 0.5,
      position = position_jitter(width = 0.02, height = 0),
      col = traps_cols[1]
    ) +
    geom_abline(slope = 0, intercept = 0, col = traps_cols[3], alpha = 0.9) +
    coord_cartesian(ylim = c(-3, 3))

  ggarrange(gg_tukey1, gg_tukey2) %>%
    annotate_figure(top = paste(
      "Tukey Anscombe - Plot for the ANOVA Residuals",
      "With (right) and Without Logarithmizing"
    ))
})
```


- are the errors independent?

If the data has some serial structure (i.e., if observations were recorded in a certain time order), we typically
want to check whether residuals close in time are more similar than residuals far apart, as this would be a
violation of the independence assumption. We can do so by using a so-called index plot where we plot the
residuals against time. For positively dependent residuals we would see time periods where most residuals
have the same sign, while for negatively dependent residuals, the residuals would âjumpâ too often from
positive to negative compared to independent residuals.

```{r indep}
map2(pollen_10, pollen_10_log, function(first, second) {
  fit_anova <- aov(conc ~ trap,
    data = first
  )
  fit_anova_log <- aov(conc ~ trap,
    data = second
  )
  resid <- residuals(fit_anova, type = "pearson")
  resid_df <- tibble(resid = resid, id = as.numeric(names(resid)))

  gg_timeline1 <- tibble(
    id = seq_len(nrow(first)),
    time = first$datetime,
    trap = first$trap
  ) %>%
    left_join(resid_df, by = "id") %>%
    ggplot(aes(x = time, y = resid)) +
    geom_point(aes(col = trap)) +
    geom_line(aes(col = trap), alpha = 0.3) +
    scale_color_manual(values = traps_cols) +
    coord_cartesian(ylim = c(0, 1000))

  resid_log <- residuals(fit_anova_log, type = "pearson")
  resid_df_log <- tibble(resid = resid_log, id = as.numeric(names(resid_log)))

  gg_timeline2 <- tibble(
    id = seq_len(nrow(second)),
    time = second$datetime,
    trap = second$trap
  ) %>%
    left_join(resid_df_log, by = "id") %>%
    ggplot(aes(x = time, y = resid)) +
    geom_point(aes(col = trap)) +
    geom_line(aes(col = trap), alpha = 0.3) +
    scale_color_manual(values = traps_cols) +
    coord_cartesian(ylim = c(0, 8))

  ggarrange(gg_timeline1, gg_timeline2, nrow = 2) %>%
    annotate_figure(top = paste("Index-Plot for the ANOVA Residuals",
                                 "With (bottom) and Without Logarithmizing"))
})
```

Especially for higher temporal resolution none of the assumption are fulfilled 
and we should clearly use robust methods to analyse this dataset.

# Correlation

We are using the robust method from Spearman, comparing Rho. 
The Spearman correlation coefficient is defined as the Pearson correlation coefficient 
between the rank variables.
https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient 
https://stats.stackexchange.com/questions/3943/kendall-tau-or-spearmans-rho

```{r corrdata}

data_corr <- map(pollen_10, ~ .x %>%
  select(conc, trap, datetime) %>%
  pivot_wider(names_from = trap, values_from = conc, datetime))

corr_matrix <- map(data_corr, ~ corr.test(
  .x %>% select(-datetime),
  use = "complete",
  method = "spearman",
  adjust = "holm",
  alpha = .05,
  ci = TRUE,
  minlength = 5
) %>%
  extract2(1))

corr_tb <- map(corr_matrix, ~ .x %>%
  as_tibble() %>%
  mutate(trap = rownames(.x))) %>%
  map_at(c(2, 3), ~ .x %>%
    mutate(
      hund = NA_real_,
      wibs = NA_real_
    )) %>%
  map(~ .x %>%
    select(trap, all_of(traps_names)) %>%
    arrange(trap))

```

```{r corrkable}

kable_corr <-  corr_tb %>%
  bind_rows() %>%
  mutate(across(where(is.numeric), round, 2)) %>%
  mutate(across(c(hund, wibs), replace_na, "-")) %>%
  setNames(c("", traps_names)) %>%
  kable(escape = FALSE) %>%
  kable_styling(c("striped", "condensed"),
    full_width = FALSE,
    font_size = 20
  ) %>%
  pack_rows("Daily", 1, 8, indent = FALSE) %>%
  pack_rows("Six-Hour", 9, 16, indent = FALSE) %>%
  pack_rows("Hourly", 17, 22, indent = FALSE) %>%
  add_header_above(c("Spearman Rho for Different Temporal Resolutions" = 9))

save_kable(kable_corr,
  file = paste0(here(), "/tables/table5_correlation.html")
)
kable_corr
```

# Kruskal-Wallis Test / Omnibus Test

Kruskal-Wallis test by rank is a non-parametric alternative to one-way ANOVA test, which extends the two-samples Wilcoxon test 
in the situation where there are more than two groups. Itâs recommended when the assumptions of one-way ANOVA test are not met. 
This tutorial describes how to compute Kruskal-Wallis test in R software. (http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r)

Assumptions
The assumptions of the Kruskal-Wallis test are similar to those for the Wilcoxon-Mann-Whitney test.

- Samples are random samples, or allocation to treatment group is random. 
- The two samples are mutually independent. 
- The measurement scale is at least ordinal, and the variable is continuous. 
- If the test is used as a test of dominance, it has no distributional assumptions. 
  If it used to compare medians, the distributions must be similar apart from their locations. 

The test is generally considered to be robust to ties. However, if ties are present they should not be concentrated 
together in one part of the distribution (they should have either a normal or uniform distribution)
https://influentialpoints.com/Training/kruskal-wallis_anova-principles-properties-assumptions.htm

The Wilcoxon signed-rank test assumes that the data are distributed symmetrically around the median. 
In other words, there should be roughly the same number of 
values above and below the median. This can be checked by visual inspection using histogram or density estimators

```{r assumption, include = FALSE}

map(pollen_10_log, ~ .x %>%
  ggplot(aes(x = conc)) +
  geom_histogram(alpha = 0.7, bins = 50, fill = traps_cols[4]) +
  geom_vline(
    xintercept = median(.x %>% pull(conc),
      na.rm = TRUE
    ),
    col = traps_cols[6]
  ) +
  ggtitle("Histogram of the Transformed Data With the Median (Grey Line)"))
```

```{r kruskal}
map(pollen_10_log, function(first) {
  kruskal.test(conc ~ trap,
    data = first %>%
      mutate(trap = factor(trap))
  )
})

```
The Null-Hypothesis that the median of all traps are equal can clearly be rejected. If that was not already clearly shown by the plots :-)

# Robust Contrasts with Confidence Intervals

https://www.researchgate.net/publication/282206980_nparcomp_An_R_Software_Package_for_Nonparametric_Multiple_Comparisons_and_Simultaneous_Confidence_Intervals 
The R package nparcomp implements a broad range of rank-based nonparametric methods for multiple comparisons. 
The single step procedures provide local test decisions in terms of multiplicity adjusted p-values and simultaneous conï¬dence intervals. 
The null hypothesis H0: p = 1/2 is signiï¬cantly rejected at 5% level of signiï¬cance for many pairwise comparisons.
Whenever the p-Value is < than 5% = the confidence interval contains 0.5 -> the effect from the factor trap is not statistically meaningful.
The Estimator can also be interpreted as a proxy for the relative difference in median for two traps.
If the Estimator is > 0.5 then the second trap tends to have larger measurements.
```{r nparcomp}
kable_nparcomp <- map2(pollen_10_log, aggregation, function(first, second) {
  npar_contr <- nparcomp::nparcomp(
    conc ~ trap,
    first,
    conf.level = 0.95,
    alternative = "two.sided",
    type = "Dunnet",
    control = "hirst"
  )

  title <- paste(
    "Robust Contrasts and Confidence Intervals for",
    second, "Measurements"
  )
  myheader <- c(title = 5)
  names(myheader) <- title

  npar_contr %>%
    extract2("Analysis") %>%
    mutate(across(where(is.numeric), round, 3)) %>%
    select(Traps = Comparison, Estimator, Lower, Upper, pValue = p.Value) %>%
    mutate(pValue = if_else(pValue < 0.05,
      cell_spec(pValue, color = "red"),
      cell_spec(pValue)
    )) %>%
    kable(escape = FALSE) %>%
    kable_styling("striped", full_width = FALSE) %>%
    add_header_above(myheader)
})

map(aggregation, function(first) {
  save_kable(kable_nparcomp,
    file = paste0(
      here(),
      "/tables/table6_nparcomp_",
      first, ".html"
    )
  )
})

kable_nparcomp$daily
kable_nparcomp$sixhour
kable_nparcomp$hourly
```
